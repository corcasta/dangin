{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import copy\n",
    "import cv2\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from typing import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to load each image, dmap, etc..\n",
    "def dataloader_dmap(dataset_path: str, ground_truth: bool = False):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): _description_\n",
    "        ground_truth (bool, optional): _description_. Defaults to False.\n",
    "\n",
    "    Yields:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    while True:\n",
    "        try:\n",
    "            render_path = dataset_path + f'/render{counter}'\n",
    "            if ground_truth:\n",
    "                dmap_path = render_path + '/dmap.npy'\n",
    "            else:\n",
    "                dmap_path = render_path + '/nndepth.npy'\n",
    "            wrench_path = render_path + '/image8.png'\n",
    "            dmap = np.load(dmap_path)                           # Depth maps are in millimeters\n",
    "            wrench_img = cv2.imread(wrench_path)\n",
    "            counter +=1\n",
    "            yield dmap, wrench_img\n",
    "        except:\n",
    "            break\n",
    "        \n",
    "def dataloader_ply(dataset_path: str):\n",
    "    counter = 0\n",
    "    while True:\n",
    "        try:\n",
    "            render_path = dataset_path + f'/render{counter}'\n",
    "            ply_path = render_path + f'/{counter}.ply'\n",
    "            ply = o3d.io.read_point_cloud(ply_path)\n",
    "            counter +=1\n",
    "            yield ply\n",
    "        except:\n",
    "            break\n",
    "    \n",
    "        \n",
    "class Stitcher():\n",
    "    def __init__(self, voxel_size=0.2, radius_normal_weight=2.0, radius_fpfh_feature_weight=5.0, max_nn_fpfh_feature=230, \n",
    "                 max_nn_normal=230, max_nn_local_reg=100, dist_correspond_checker_weight=1.5, edge_length_correspond_checker=0.95,\n",
    "                 ransac_max_iterations=10000000, ransac_confidence=0.999, max_correspond_dist=0.2):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            voxel_size (float, optional): _description_. Defaults to 0.2.\n",
    "            radius_normal_weight (float, optional): _description_. Defaults to 2.0.\n",
    "            radius_fpfh_feature_weight (float, optional): _description_. Defaults to 5.0.\n",
    "            max_nn_fpfh_feature (int, optional): _description_. Defaults to 230.\n",
    "            max_nn_normal (int, optional): _description_. Defaults to 230.\n",
    "            max_nn_local_reg (int, optional): _description_. Defaults to 100.\n",
    "            dist_correspond_checker_weight (float, optional): _description_. Defaults to 1.5.\n",
    "            edge_length_correspond_checker (float, optional): _description_. Defaults to 0.95.\n",
    "            ransac_max_iterations (int, optional): _description_. Defaults to 10000000.\n",
    "            ransac_confidence (float, optional): _description_. Defaults to 0.999.\n",
    "            max_correspond_dist (float, optional): _description_. Defaults to 0.2.\n",
    "        \"\"\"\n",
    "        self.voxel_size = voxel_size\n",
    "        self.max_nn_normal = max_nn_normal\n",
    "        self.radius_normal =  voxel_size * radius_normal_weight\n",
    "        self.radius_fpfh_feature = voxel_size * radius_fpfh_feature_weight\n",
    "        self.max_nn_fpfh_feature = max_nn_fpfh_feature\n",
    "        self.dist_correspond_checker = voxel_size * dist_correspond_checker_weight      # G\n",
    "        self.edge_length_correspond_checker = edge_length_correspond_checker            # G\n",
    "        self.ransac_max_iterations = ransac_max_iterations                              # G\n",
    "        self.ransac_confidence = ransac_confidence                                      # G\n",
    "        self.max_correspond_dist = max_correspond_dist\n",
    "        self.radius_local_reg = voxel_size * radius_normal_weight\n",
    "        self.max_nn_local_reg = max_nn_local_reg\n",
    "        self.current_transform = np.eye(4)                                              # Identity Matrix\n",
    "        self.transforms_history = [self.current_transform]                              # This will store all transforms/poses of each pcd\n",
    "                                                                                        # is really helpfull to evaluate metrics and comparisons.\n",
    "    \n",
    "    @classmethod\n",
    "    def generate_pointcloud(cls, img: np.array, dmap: np.array, pcd: o3d.cpu.pybind.geometry.PointCloud) -> None:\n",
    "        \"\"\"\n",
    "        Populates point cloud given the information provided by the image and depth map.\n",
    "\n",
    "        Args:\n",
    "            img (np.array): PNG image\n",
    "            dmap (np.array): Depth map/image\n",
    "            pcd (o3d.cpu.pybind.geometry.PointCloud): Point cloud object\n",
    "        \"\"\"\n",
    "        height, width = dmap.shape\n",
    "        xyz = np.ones(shape=(height, width, 3))  \n",
    "        x = np.arange(width).reshape((1, width))\n",
    "        y = np.arange(height).reshape((height, 1))\n",
    "        xyz[:, :, 0] = xyz[:, :, 0]*x                                 # Fill with horizontal indexes\n",
    "        xyz[:, :, 1] = xyz[:, :, 1]*y                                 # Fill with vertical indexes  \n",
    "        xyz[:, :, 2] = dmap                                           # Fill with depth, z coords w.r.t camera frame  \n",
    "        xyz[:, :, 0] = 0.1655 * (xyz[:, :, 0]-80) * xyz[:, :, 2]/80   # Updated with x coords w.r.t camera frame \n",
    "        xyz[:, :, 1] = 0.1655 * (xyz[:, :, 1]-80) * xyz[:, :, 2]/80   # Updated with y coords w.r.t camera frame \n",
    "        xyz = xyz.reshape(width*height, -1)                           # Shape required by open3d\n",
    "        rgb = img.reshape((width*height, -1))[::-1]\n",
    "        # *********************************************************\n",
    "        # pcd is a mutable object so no need to return the updated \n",
    "        # object as modifications are applied to the original\n",
    "        pcd.points = o3d.utility.Vector3dVector(xyz)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(rgb)\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def merge_point_clouds(cls, source: o3d.cpu.pybind.geometry.PointCloud, target: o3d.cpu.pybind.geometry.PointCloud, transform: np.array) -> None:\n",
    "        \"\"\"\n",
    "        Transform source point cloud to target point cloud reference frame and merges it in target point cloud.\n",
    "        *Changes are reflected in target object itself as this behvaious is same as being passed by reference in c++ thus no need to return anything.\n",
    "\n",
    "        Args:\n",
    "            source (o3d.cpu.pybind.geometry.PointCloud): Point cloud to be transformed.\n",
    "            target (o3d.cpu.pybind.geometry.PointCloud): Point cloud that will be merged with the transformed source point cloud.\n",
    "            transform (np.array):                        Homogeneous transformation matrix of shape 4x4. This matrix MUST represent the transform form source to target\n",
    "        \"\"\"\n",
    "        source.transform(transform)\n",
    "        target += source\n",
    "        # Is not necessary to return source since changes are applied directly to the object \n",
    "        \n",
    "        \n",
    "    def point_cloud_start_location(self, pcd: o3d.cpu.pybind.geometry.PointCloud, transform: np.array) -> None:\n",
    "        \"\"\"\n",
    "        Transforms both point clouds (source & target) to the same initial location/pose given by the transform matrix.\n",
    "        *Changes are reflected in source and target object itself as this behvaious is same as being passed by reference in c++ thus no need to return anything.\n",
    "\n",
    "        Args:\n",
    "            pcd (o3d.cpu.pybind.geometry.PointCloud): Point cloud to be transformed\n",
    "            target (o3d.cpu.pybind.geometry.PointCloud): Point cloud to be transformed\n",
    "            transform (np.array):                        Homogeneous transformation matrix shape 4x4. This matrix represent the starting pose/location for both point clouds\n",
    "        \"\"\"\n",
    "        pcd.transform(transform)\n",
    "        \n",
    "         \n",
    "    #def point_clouds_start_location(self, source: o3d.cpu.pybind.geometry.PointCloud, target: o3d.cpu.pybind.geometry.PointCloud, transform: np.array) -> None:\n",
    "    #    \"\"\"\n",
    "    #    Transforms both point clouds (source & target) to the same initial location/pose given by the transform matrix.\n",
    "    #    *Changes are reflected in source and target object itself as this behvaious is same as being passed by reference in c++ thus no need to return anything.\n",
    "    #\n",
    "    #    Args:\n",
    "    #        source (o3d.cpu.pybind.geometry.PointCloud): Point cloud to be transformed\n",
    "    #        target (o3d.cpu.pybind.geometry.PointCloud): Point cloud to be transformed\n",
    "    #        transform (np.array):                        Homogeneous transformation matrix shape 4x4. This matrix represent the starting pose/location for both point clouds\n",
    "    #    \"\"\"\n",
    "    #    source.transform(transform)\n",
    "    #    target.transform(transform) \n",
    "        \n",
    "        \n",
    "    def global_and_icp_registration_v2(self, source: o3d.cpu.pybind.geometry.PointCloud, target: o3d.cpu.pybind.geometry.PointCloud) -> o3d.cpu.pybind.pipelines.registration.RegistrationResult:\n",
    "        \"\"\"\n",
    "        Calculates the results necessary for transforming source point cloud to target point cloud as best as possible. \n",
    "\n",
    "        Args:\n",
    "            source (o3d.cpu.pybind.geometry.PointCloud): Point cloud that is looking to be transformed\n",
    "            target (o3d.cpu.pybind.geometry.PointCloud): Point Cloud that works as the reference base\n",
    "\n",
    "        Returns:\n",
    "            o3d.cpu.pybind.pipelines.registration.RegistrationResult: Object that contains registration results such as transformation, correspondence_set, fitness, inlier_rmse\n",
    "        \"\"\"\n",
    "        source_down, source_fpfh = self._preprocess_point_cloud(source)\n",
    "        target_down, target_fpfh = self._preprocess_point_cloud(target)\n",
    "        result_ransac = self._global_registration(source_down, target_down, source_fpfh, target_fpfh)\n",
    "        result_icp = self._local_registration(source, target, result_ransac.transformation)\n",
    "        return result_icp\n",
    "    \n",
    "    \n",
    "    def set_current_transform(self, transform: np.array) -> None:\n",
    "        \"\"\"\n",
    "        Updates current transform. The input MUST represent the transform of the newest point cloud to the world frame.\n",
    "        E.g.  current_transform = stitcher.current_transform @ result_icp.transformation  \n",
    "\n",
    "        Args:\n",
    "            transform (np.array): Homogeneous transformation matrix shape 4x4. \n",
    "        \"\"\"\n",
    "        self.current_transform = transform\n",
    "    \n",
    "\n",
    "\n",
    "    def _preprocess_point_cloud(self, pcd: o3d.cpu.pybind.geometry.PointCloud) -> tuple[o3d.cpu.pybind.geometry.PointCloud, o3d.cpu.pybind.pipelines.registration.Feature]:\n",
    "        \"\"\"\n",
    "        Creates a simplified point cloud (downsampled) of the input point cloud.\n",
    "\n",
    "        Args:\n",
    "            pcd (o3d.cpu.pybind.geometry.PointCloud): Point cloud\n",
    "\n",
    "        Returns:\n",
    "            tuple[o3d.cpu.pybind.geometry.PointCloud, \n",
    "            o3d.cpu.pybind.pipelines.registration.Feature]: Tuple comtaining simplified point cloud  and its corresponding features descriptor.\n",
    "        \"\"\"\n",
    "        pcd_down = pcd.voxel_down_sample(self.voxel_size)\n",
    "        pcd_down = self.outlier_removal(pcd_down)\n",
    "        pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=self.radius_normal, max_nn=self.max_nn_normal))\n",
    "        pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(pcd_down, o3d.geometry.KDTreeSearchParamHybrid(radius=self.radius_fpfh_feature, max_nn=self.max_nn_fpfh_feature))\n",
    "        return pcd_down, pcd_fpfh\n",
    "\n",
    "\n",
    "    def outlier_removal(self, pcd):\n",
    "        #pcd, ind = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)\n",
    "        pcd, ind = pcd.remove_radius_outlier(nb_points=25, radius=0.5)\n",
    "        return pcd\n",
    "    \n",
    "    def _global_registration(self, source_down: o3d.cpu.pybind.geometry.PointCloud, \n",
    "                             target_down: o3d.cpu.pybind.geometry.PointCloud, \n",
    "                             source_fpfh: o3d.cpu.pybind.pipelines.registration.Feature, \n",
    "                             target_fpfh:o3d.cpu.pybind.pipelines.registration.Feature) -> o3d.cpu.pybind.pipelines.registration.RegistrationResult:\n",
    "        \"\"\"\n",
    "        Calculates the results necessary for transforming source point cloud to target point cloud as a best initial allignment.\n",
    "        Point clouds can be placed anywehere, global registration will produce the a rough best alignment. This requires fine tunning/local registration\n",
    "        to get better allignment. \n",
    "\n",
    "        Args:\n",
    "            source_down (o3d.cpu.pybind.geometry.PointCloud): Point cloud that is looking to be transformed.\n",
    "            target_down (o3d.cpu.pybind.geometry.PointCloud): Point cloud that works as the reference base.\n",
    "            source_fpfh (o3d.cpu.pybind.pipelines.registration.Feature): Point cloud corresponding features descriptor.\n",
    "            target_fpfh (o3d.cpu.pybind.pipelines.registration.Feature): Point cloud corresponding features descriptor.\n",
    "\n",
    "        Returns:\n",
    "            o3d.cpu.pybind.pipelines.registration.RegistrationResult: Object that contains registration results such as transformation, correspondence_set, fitness, inlier_rmse\n",
    "        \"\"\"\n",
    "        result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "            source_down, target_down, source_fpfh, target_fpfh, True, self.dist_correspond_checker,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(False), 3, \n",
    "            [\n",
    "                o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(self.edge_length_correspond_checker),\n",
    "                o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(self.dist_correspond_checker)\n",
    "            ], \n",
    "            o3d.pipelines.registration.RANSACConvergenceCriteria(self.ransac_max_iterations, self.ransac_confidence))\n",
    "        return result\n",
    "\n",
    "\n",
    "    def _local_registration(self, source: o3d.cpu.pybind.geometry.PointCloud, target: o3d.cpu.pybind.geometry.PointCloud, transform: np.array) -> o3d.cpu.pybind.pipelines.registration.RegistrationResult:\n",
    "        \"\"\"\n",
    "        Calculates the results necessary for transforming source point cloud to target point cloud as best as possible.\n",
    "        Point clouds need to be placed together on the area they are meant to be matched. As this method creates only fine tunning allignment. \n",
    "\n",
    "        Args:\n",
    "            source (o3d.cpu.pybind.geometry.PointCloud): Point cloud that is looking to be transformed.\n",
    "            target (o3d.cpu.pybind.geometry.PointCloud): Point cloud that works as the reference base.\n",
    "            transform (np.array):                        Homogeneous transformation matrix shape 4x4. This matrix represents the global alignment between the point clouds (source -> target)\n",
    "\n",
    "        Returns:\n",
    "            o3d.cpu.pybind.pipelines.registration.RegistrationResult: Object that contains registration results such as transformation, correspondence_set, fitness, inlier_rmse\n",
    "        \"\"\"\n",
    "        source.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=self.radius_local_reg, max_nn=self.max_nn_local_reg))\n",
    "        target.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=self.radius_local_reg, max_nn=self.max_nn_local_reg))\n",
    "        result = o3d.pipelines.registration.registration_icp(source, target, self.max_correspond_dist, transform, o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "        #result = o3d.pipelines.registration.registration_colored_icp(source, target, voxel_size, result.transformation)\n",
    "        return result\n",
    "\n",
    "\n",
    "    #def global_and_icp_registration(self, source: o3d.cpu.pybind.geometry.PointCloud, target: o3d.cpu.pybind.geometry.PointCloud) -> np.array:\n",
    "        #    \"\"\"\n",
    "        #    Calculates the transformation matrix necessary for transforming source point cloud to target point cloud as best as possible.\n",
    "        #\n",
    "        #    Args:\n",
    "        #        source (o3d.cpu.pybind.geometry.PointCloud): Point cloud that is looking to be transformed\n",
    "        #        target (o3d.cpu.pybind.geometry.PointCloud): Point Cloud that works as a reference base\n",
    "        #\n",
    "        #    Returns:\n",
    "        #        np.array: Homogeneous transformation matrix shape 4x4. This matrix represents the transform form source to target\n",
    "        #    \"\"\"\n",
    "        #    self._set_point_clouds_init_transform(source, target)\n",
    "        #    source_down, target_down, source_fpfh, target_fpfh = self._simplify_point_clouds(source, target)\n",
    "        #    result_ransac = self._global_registration(source_down, target_down, source_fpfh, target_fpfh)\n",
    "        #    result_icp = self._local_registration(source, target, result_ransac.transformation)\n",
    "        #    self.current_transform = self.current_transform @ result_icp.transformation\n",
    "        #    self.merge_point_clouds(source, target, result_icp.transformation)\n",
    "        #    # At this point source contains the merge between both point clouds\n",
    "        #    # Is not necessary to return source since changes are applied directly to the object\n",
    "        #    return result_icp.transformation\n",
    "        #\n",
    "        #\n",
    "        #def _set_point_clouds_init_transform(self, source: o3d.cpu.pybind.geometry.PointCloud, target: o3d.cpu.pybind.geometry.PointCloud) -> None:\n",
    "        #    target.transform(self.current_transform)\n",
    "        #    source.transform(self.current_transform)\n",
    "        \n",
    "        \n",
    "        #def _simplify_point_clouds(self, source: o3d.cpu.pybind.geometry.PointCloud, target: o3d.cpu.pybind.geometry.PointCloud) -> tuple[o3d.cpu.pybind.geometry.PointCloud,\n",
    "        #                                                                                                                                  o3d.cpu.pybind.geometry.PointCloud,\n",
    "        #                                                                                                                                  o3d.cpu.pybind.pipelines.registration.Feature,\n",
    "        #                                                                                                                                  o3d.cpu.pybind.pipelines.registration.Feature]:\n",
    "        #    \"\"\"_summary_\n",
    "        #\n",
    "        #    Args:\n",
    "        #        source (o3d.cpu.pybind.geometry.PointCloud): _description_\n",
    "        #        target (o3d.cpu.pybind.geometry.PointCloud): _description_\n",
    "        #\n",
    "        #    Returns:\n",
    "        #        tuple[o3d.cpu.pybind.geometry.PointCloud, \n",
    "        #              o3d.cpu.pybind.geometry.PointCloud, \n",
    "        #              o3d.cpu.pybind.pipelines.registration.Feature, \n",
    "        #              o3d.cpu.pybind.pipelines.registration.Feature]: Tuple containing simplified source and target pointclouds and their corresponding features descriptors. \n",
    "        #    \"\"\"\n",
    "        #    source_down, source_fpfh = self._preprocess_point_cloud(source)\n",
    "        #    target_down, target_fpfh = self._preprocess_point_cloud(target)\n",
    "        #    #source_down, outlier_index = source_down.remove_radius_outlier(nb_points=25,radius=0.5)\n",
    "        #    #source_down, outlier_index = target_down.remove_radius_outlier(nb_points=25,radius=0.5)\n",
    "        #    return source_down, target_down, source_fpfh, target_fpfh\n",
    "\n",
    "\n",
    "def get_transform(img_query, img_target):\n",
    "    orb = cv2.ORB_create()\n",
    "    matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    kpts_query,  desc_query = orb.detectAndCompute(img_query, None)\n",
    "    kpts_target, desc_target = orb.detectAndCompute(img_target, None)\n",
    "    matches = matcher.match(desc_query, desc_target)\n",
    "    kpts_query_filtered = []\n",
    "    kpts_target_filtered = []\n",
    "    for match in matches:\n",
    "        kpts_query_filtered = kpts_query[match.queryIdx]\n",
    "        kpts_target_filtered = kpts_target[match.trainIdx]\n",
    "    fund_mtx = cv2.findFundamentalMat(kpts_query_filtered, \n",
    "                                      kpts_target_filtered, \n",
    "                                      cv2.FM_RANSAC, 3, 0.99)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 0\n",
      "Image: 1\n",
      "Image: 2\n",
      "Image: 3\n",
      "Image: 4\n",
      "Image: 5\n",
      "Image: 6\n",
      "Image: 7\n",
      "Image: 8\n",
      "Image: 9\n",
      "Image: 10\n",
      "Image: 11\n",
      "Image: 12\n",
      "Image: 13\n",
      "Image: 14\n",
      "Image: 15\n",
      "Image: 16\n",
      "Image: 17\n",
      "Image: 18\n",
      "Image: 19\n",
      "Image: 20\n",
      "Image: 21\n",
      "Image: 22\n",
      "Image: 23\n",
      "Image: 24\n",
      "Image: 25\n",
      "Image: 26\n",
      "Image: 27\n",
      "Image: 28\n",
      "Image: 29\n",
      "Image: 30\n",
      "Image: 31\n",
      "Image: 32\n",
      "Image: 33\n",
      "Image: 34\n",
      "Image: 35\n",
      "Image: 36\n",
      "Image: 37\n",
      "Image: 38\n",
      "Image: 39\n",
      "Image: 40\n",
      "Image: 41\n",
      "Image: 42\n",
      "Image: 43\n",
      "Image: 44\n",
      "Image: 45\n",
      "Image: 46\n",
      "Image: 47\n",
      "Image: 48\n",
      "Image: 49\n",
      "Image: 50\n",
      "Image: 51\n",
      "Image: 52\n",
      "Image: 53\n",
      "Image: 54\n",
      "Image: 55\n",
      "Image: 56\n",
      "Image: 57\n",
      "Image: 58\n",
      "Image: 59\n",
      "Image: 60\n",
      "Image: 61\n",
      "Image: 62\n",
      "Image: 63\n",
      "Image: 64\n",
      "Image: 65\n",
      "Image: 66\n",
      "Image: 67\n",
      "Image: 68\n",
      "Image: 69\n",
      "Image: 70\n",
      "Image: 71\n",
      "Image: 72\n",
      "Image: 73\n",
      "Image: 74\n",
      "Image: 75\n",
      "Image: 76\n",
      "Image: 77\n",
      "Image: 78\n",
      "Image: 79\n",
      "Image: 80\n",
      "Image: 81\n",
      "Image: 82\n",
      "Image: 83\n",
      "Image: 84\n",
      "Image: 85\n",
      "Image: 86\n",
      "Image: 87\n",
      "Image: 88\n",
      "Image: 89\n",
      "Image: 90\n",
      "Image: 91\n",
      "Image: 92\n",
      "Image: 93\n",
      "Image: 94\n",
      "Image: 95\n",
      "Image: 96\n",
      "Image: 97\n",
      "Image: 98\n",
      "Image: 99\n",
      "Image: 100\n",
      "Image: 101\n",
      "Image: 102\n",
      "Image: 103\n",
      "Image: 104\n",
      "Image: 105\n",
      "Image: 106\n",
      "Image: 107\n",
      "Image: 108\n",
      "Image: 109\n",
      "Image: 110\n",
      "Image: 111\n",
      "Image: 112\n",
      "Image: 113\n",
      "Image: 114\n",
      "Image: 115\n",
      "Image: 116\n",
      "Image: 117\n",
      "Image: 118\n",
      "Image: 119\n",
      "Image: 120\n",
      "Image: 121\n",
      "Image: 122\n",
      "Image: 123\n",
      "Image: 124\n",
      "Image: 125\n",
      "Image: 126\n",
      "Image: 127\n",
      "Image: 128\n",
      "Image: 129\n",
      "Image: 130\n",
      "Image: 131\n",
      "Image: 132\n",
      "Image: 133\n",
      "Image: 134\n",
      "Image: 135\n",
      "Image: 136\n",
      "Image: 137\n",
      "Image: 138\n",
      "Image: 139\n",
      "Image: 140\n",
      "Image: 141\n",
      "Image: 142\n",
      "Image: 143\n",
      "Image: 144\n",
      "Image: 145\n",
      "Image: 146\n",
      "Image: 147\n",
      "Image: 148\n",
      "Image: 149\n",
      "Image: 150\n",
      "Image: 151\n",
      "Image: 152\n",
      "Image: 153\n",
      "Image: 154\n",
      "Image: 155\n",
      "Image: 156\n",
      "Image: 157\n",
      "Image: 158\n",
      "Image: 159\n",
      "Image: 160\n",
      "Image: 161\n",
      "Image: 162\n",
      "Image: 163\n",
      "Image: 164\n",
      "Image: 165\n",
      "Image: 166\n",
      "Image: 167\n",
      "Image: 168\n",
      "Image: 169\n",
      "Image: 170\n",
      "Image: 171\n",
      "Image: 172\n",
      "Image: 173\n",
      "Image: 174\n",
      "Image: 175\n",
      "Image: 176\n",
      "Image: 177\n",
      "Image: 178\n",
      "Image: 179\n",
      "Image: 180\n",
      "Image: 181\n",
      "Image: 182\n",
      "Image: 183\n",
      "Image: 184\n",
      "Image: 185\n",
      "Image: 186\n",
      "Image: 187\n",
      "Image: 188\n",
      "Image: 189\n",
      "Image: 190\n",
      "Image: 191\n",
      "Image: 192\n",
      "Image: 193\n",
      "Image: 194\n",
      "Image: 195\n",
      "Image: 196\n",
      "Image: 197\n",
      "Image: 198\n",
      "Image: 199\n"
     ]
    }
   ],
   "source": [
    "#  *** **************** ******************** ******************** ******************** ******************** ***\n",
    "#  ******************** This approach is for stitching NEW point cloud with PREVIOUS. ******************** \n",
    "#  *** **************** ******************** ******************** ******************** ******************** ***\n",
    "\n",
    "root_path = str(pathlib.Path('').parent.resolve().parent)\n",
    "\n",
    "# Select one dataset\n",
    "dataset = 'LA200'\n",
    "dataset_path = root_path + f'/datasets/{dataset}'\n",
    "\n",
    "# Represents how many individual point clouds are going to be grouped\n",
    "rolling_window = 5\n",
    "pcd_size = 128*128\n",
    "rolling_window_total_points = rolling_window * pcd_size\n",
    "    \n",
    "stitcher = Stitcher()\n",
    "dataset = dataloader(dataset_path, ground_truth=True)\n",
    "point_cloud_0 = o3d.geometry.PointCloud()\n",
    "point_cloud_1 = o3d.geometry.PointCloud()\n",
    "\n",
    "dmap_0, img_0 = next(dataset)\n",
    "stitcher.generate_pointcloud(img_0, dmap_0, point_cloud_0)\n",
    "point_cloud_0 = stitcher.outlier_removal(point_cloud_0)\n",
    "\n",
    "history_point_cloud = history_point_cloud_down = copy.deepcopy(point_cloud_0)\n",
    "history_points_xyz = np.array(history_point_cloud.points) \n",
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window(height=1000, width=1000)\n",
    "vis.add_geometry(history_point_cloud_down)\n",
    "\n",
    "print(\"Image: 0\")\n",
    "for i, package in enumerate(dataset):\n",
    "    dmap_1, img_1 = package\n",
    "    stitcher.generate_pointcloud(img_1, dmap_1, point_cloud_1)\n",
    "    point_cloud_1 = stitcher.outlier_removal(point_cloud_1)\n",
    "    \n",
    "    point_cloud_1_temp = copy.deepcopy(point_cloud_1)\n",
    "    \n",
    "    if len(history_points_xyz) >= (rolling_window_total_points):\n",
    "        pass\n",
    "    else:\n",
    "        stitcher.point_cloud_start_location(point_cloud_0, stitcher.current_transform)\n",
    "        \n",
    "    stitcher.point_cloud_start_location(point_cloud_1, stitcher.current_transform)                     # As the name implies first initialize both pcls on specified loc.\n",
    "    result_icp = stitcher.global_and_icp_registration_v2(point_cloud_1, point_cloud_0)                 # Calculate the best transform starting between both point clouds\n",
    "    current_transform = stitcher.current_transform @ result_icp.transformation                         # Calculate the new current transform of the trayectory. \n",
    "    stitcher.set_current_transform(current_transform)                                                  # This is useful for the next CONSECUTIVE pcl. As the starting loc.\n",
    "    \n",
    "    history_point_cloud += point_cloud_1.transform(result_icp.transformation)\n",
    "    \n",
    "    vis.update_geometry(history_point_cloud_down)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "    \n",
    "    history_points_xyz = np.array(history_point_cloud.points)\n",
    "    \n",
    "    if len(history_points_xyz) >= (rolling_window_total_points): \n",
    "        point_cloud_0 = o3d.geometry.PointCloud()\n",
    "        point_cloud_0.points = o3d.utility.Vector3dVector(history_points_xyz[-(rolling_window_total_points):, :])\n",
    "    else:\n",
    "        point_cloud_0 = copy.deepcopy(point_cloud_1_temp)\n",
    "\n",
    "    print(f\"Image: {i+1}\")\n",
    "    if (i+1) == 199:\n",
    "        break\n",
    "\n",
    "vis.destroy_window()\n",
    "o3d.visualization.draw_geometries([history_point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 160)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmap_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  *** **************** ******************** ******************** ******************** ******************** ***\n",
    "#  ******************** V2-This approach is for stitching NEW point cloud with PREVIOUS. ******************** \n",
    "#  *** **************** ******************** ******************** ******************** ******************** ***\n",
    "\n",
    "root_path = str(pathlib.Path('').parent.resolve().parent)\n",
    "\n",
    "# Select one dataset\n",
    "dataset = 'LA200_inf'\n",
    "dataset_path = root_path + f'/datasets/{dataset}'\n",
    "\n",
    "# Represents how many individual point clouds are going to be grouped\n",
    "rolling_window = 10\n",
    "pcd_size = 128*128\n",
    "rolling_window_total_points = rolling_window * pcd_size\n",
    "    \n",
    "stitcher = Stitcher()\n",
    "dataset = dataloader_ply(dataset_path)\n",
    "point_cloud_0 = o3d.geometry.PointCloud()\n",
    "point_cloud_1 = o3d.geometry.PointCloud()\n",
    "\n",
    "point_cloud_0 = next(dataset)\n",
    "point_cloud_0 = stitcher.outlier_removal(point_cloud_0)\n",
    "#stitcher.generate_pointcloud(img_0, dmap_0, point_cloud_0)\n",
    "\n",
    "history_point_cloud = copy.deepcopy(point_cloud_0)\n",
    "history_points_xyz = np.array(history_point_cloud.points) \n",
    "\n",
    "#o3d.visualization.draw_geometries([point_cloud_0])\n",
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window(height=1000, width=1000)\n",
    "vis.add_geometry(history_point_cloud)\n",
    "\n",
    "\n",
    "for i, package in enumerate(dataset):\n",
    "    point_cloud_1 = package\n",
    "    point_cloud_1 = stitcher.outlier_removal(point_cloud_1)\n",
    "    point_cloud_1_temp = copy.deepcopy(point_cloud_1)\n",
    "    \n",
    "    if len(history_points_xyz) >= (rolling_window_total_points):\n",
    "        pass\n",
    "    else:\n",
    "        stitcher.point_cloud_start_location(point_cloud_0, stitcher.current_transform)\n",
    "        \n",
    "    stitcher.point_cloud_start_location(point_cloud_1, stitcher.current_transform)                     # As the name implies first initialize both pcls on specified loc.\n",
    "    result_icp = stitcher.global_and_icp_registration_v2(point_cloud_1, point_cloud_0)                 # Calculate the best transform starting between both point clouds\n",
    "    current_transform = stitcher.current_transform @ result_icp.transformation                         # Calculate the new current transform of the trayectory. \n",
    "    stitcher.set_current_transform(current_transform)                                                  # This is useful for the next CONSECUTIVE pcl. As the starting loc.\n",
    "    \n",
    "    history_point_cloud += point_cloud_1.transform(result_icp.transformation)\n",
    "    \n",
    "    vis.update_geometry(history_point_cloud)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "    \n",
    "    history_points_xyz = np.array(history_point_cloud.points)\n",
    "    if len(history_points_xyz) >= (rolling_window_total_points): \n",
    "        point_cloud_0 = o3d.geometry.PointCloud()\n",
    "        point_cloud_0.points = o3d.utility.Vector3dVector(history_points_xyz[-(rolling_window_total_points):, :])\n",
    "    else:\n",
    "        point_cloud_0 = copy.deepcopy(point_cloud_1_temp)\n",
    "    \n",
    "    #if (i+1)%50 == 0:\n",
    "    #    o3d.visualization.draw_geometries([history_point_cloud])\n",
    "    \n",
    "    if (i+1) == 199:\n",
    "        break\n",
    "vis.destroy_window()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([history_point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  *** **************** ******************** ******************** ******************** ******************** ***\n",
    "#  ******************** This approach is for stitching all point clouds one after another. ******************** \n",
    "#  *** **************** ******************** ******************** ******************** ******************** ***\n",
    "\n",
    "root_path = str(pathlib.Path('').parent.resolve().parent)\n",
    "\n",
    "# Select one dataset\n",
    "dataset = 'LA10'\n",
    "dataset_path = root_path + f'/datasets/{dataset}'\n",
    "\n",
    "# Represents how many individual point clouds are going to be grouped\n",
    "group_size = 5  \n",
    "stitcher = Stitcher()\n",
    "dataset = dataloader(dataset_path)\n",
    "\n",
    "point_cloud_0 = o3d.geometry.PointCloud()\n",
    "point_cloud_1 = o3d.geometry.PointCloud()\n",
    "history_point_cloud = copy.deepcopy(point_cloud_0)\n",
    "\n",
    "dmap_0, img_0 = next(dataset)\n",
    "stitcher.generate_pointcloud(img_0, dmap_0, point_cloud_0) \n",
    "#stitcher.transform_2_world_frame(point_cloud_0)\n",
    "\n",
    "for i, package in enumerate(dataset):\n",
    "    dmap_1, img_1 = package\n",
    "    stitcher.generate_pointcloud(img_1, dmap_1, point_cloud_1)\n",
    "    \n",
    "    point_cloud_1_temp = copy.deepcopy(point_cloud_1)\n",
    "    print(f\"PCL1_TEMP: {np.array(point_cloud_1_temp.points)[0,:]}\")\n",
    "    \n",
    "    _ = stitcher.global_and_icp_registration(point_cloud_1, point_cloud_0)\n",
    "    print(f\"PCL1_FINAL: {np.array(point_cloud_1.points)[0,:]}\")\n",
    "    merged_point_clouds = copy.deepcopy(point_cloud_1)\n",
    "    history_point_cloud += merged_point_clouds\n",
    "    \n",
    "    \n",
    "    # The next starting point_cloud_0point is going to be the previous point cloud\n",
    "    point_cloud_0 = copy.deepcopy(point_cloud_1_temp)\n",
    "    \n",
    "    if (i+1)%10 == 0:\n",
    "        #point_cloud_0.paint_uniform_color([1, 0, 0])\n",
    "        #point_cloud_1.paint_uniform_color([0, 1, 0])\n",
    "        o3d.visualization.draw_geometries([history_point_cloud])\n",
    "    if (i+1) == 1:\n",
    "        break\n",
    "    print(\"Iteration: \",i)\n",
    "    \n",
    "# Final view of the stitched object    \n",
    "#point_cloud_0, _ = point_cloud_0.remove_radius_outlier(nb_points=25, radius=0.5)\n",
    "\n",
    "#o3d.visualization.draw_geometries([point_cloud_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[-5.74930286e-05,  9.99999993e-01,  1.02630216e-04,  1.32672791e-03],\n",
    "              [-7.75953563e-05, -1.02634677e-04,  9.99999992e-01,  1.28570857e-03],\n",
    "              [ 9.99999995e-01,  5.74850645e-05,  7.76012565e-05, -4.10673829e-03],\n",
    "              [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])\n",
    "\n",
    "b = np.array([[ 6.98218409e-05,  9.99999997e-01, -2.49201977e-05, -8.26632295e-03],\n",
    "              [-2.30308338e-07,  2.49202138e-05,  1.00000000e+00,  3.30637134e-02],\n",
    "              [ 9.99999998e-01, -6.98218352e-05,  2.32048313e-07, -4.69649984e-05],\n",
    "              [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])\n",
    "\n",
    "trans_init = np.eye(4)\n",
    "        \n",
    "\n",
    "\n",
    "root_path = str(pathlib.Path('').parent.resolve().parent)\n",
    "# Select one dataset\n",
    "dataset = 'LA10'\n",
    "dataset_path = root_path + f'/datasets/{dataset}'\n",
    "dataset = dataloader(dataset_path)\n",
    "stitcher = Stitcher()\n",
    "\n",
    "point_cloud_0 = o3d.geometry.PointCloud()\n",
    "point_cloud_1 = o3d.geometry.PointCloud()\n",
    "\n",
    "dmap_0, img_0 = next(dataset)\n",
    "stitcher.generate_pointcloud(img_0, dmap_0, point_cloud_0) \n",
    "\n",
    "dmap_1, img_1 = next(dataset)\n",
    "stitcher.generate_pointcloud(img_1, dmap_1, point_cloud_1) \n",
    "\n",
    "point_cloud_0.paint_uniform_color([0, 0, 1])\n",
    "point_cloud_1.paint_uniform_color([1, 0, 0])\n",
    "\n",
    "##point_cloud_1 = point_cloud_1.transform(a)\n",
    "##point_cloud_0.transform(trans_init)\n",
    "#point_cloud_0.transform(b @ trans_init)\n",
    "#point_cloud_0 += point_cloud_1\n",
    "\n",
    "point_cloud_0.transform(trans_init)\n",
    "\n",
    "world_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
    "pcd_0_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=1, origin=trans_init[:3, -1])\n",
    "pcd_0_frame.rotate(trans_init[:3, :3])\n",
    "\n",
    "o3d.visualization.draw_geometries([point_cloud_0, point_cloud_1, pcd_0_frame])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  *** **************** ******************** ******************** ******************** ******************** ***\n",
    "#  ******************** This approach is in DEVELOPMENT. ******************** \n",
    "#  *** **************** ******************** ******************** ******************** ******************** ***\n",
    "\n",
    "root_path = str(pathlib.Path('').parent.resolve().parent)\n",
    "\n",
    "# Select one dataset\n",
    "dataset = 'LA10'\n",
    "dataset_path = root_path + f'/datasets/{dataset}'\n",
    "\n",
    "# Represents how many individual point clouds are going to be grouped\n",
    "group_size = 5  \n",
    "stitcher = Stitcher()\n",
    "dataset = dataloader(dataset_path)\n",
    "\n",
    "point_cloud_0 = o3d.geometry.PointCloud()\n",
    "point_cloud_1 = o3d.geometry.PointCloud()\n",
    "\n",
    "dmap_0, img_0 = next(dataset)\n",
    "stitcher.generate_pointcloud(img_0, dmap_0, point_cloud_0) \n",
    "\n",
    "current_transform = stitcher.init_transform\n",
    "whole_point_cloud = copy.deepcopy(point_cloud_0)\n",
    "\n",
    "for i, package in enumerate(dataset):\n",
    "    \n",
    "    dmap_1, img_1 = package\n",
    "    stitcher.generate_pointcloud(img_1, dmap_1, point_cloud_1)\n",
    "    \n",
    "    # Original, Before any transformation\n",
    "    point_cloud_1_temp = copy.deepcopy(point_cloud_1)    \n",
    "\n",
    "    # From current image to previous image\n",
    "    # Once the following line is executed point_cloud_1 will be transformed but we returned the transformed applied\n",
    "    icp_transform = stitcher.global_and_icp_registration(point_cloud_0, point_cloud_1)\n",
    "    \n",
    "    point_cloud_0 = copy.deepcopy(point_cloud_1_temp)\n",
    "\n",
    "    current_transform = current_transform @ icp_transform \n",
    "    point_cloud_1_temp = point_cloud_1_temp.transform(icp_transform)\n",
    "    \n",
    "    whole_point_cloud += point_cloud_1_temp\n",
    "    point_cloud_1 = o3d.geometry.PointCloud()\n",
    "    \n",
    "    \n",
    "    if (i+1)%1 == 0:\n",
    "        print(\"dddd\")\n",
    "        o3d.visualization.draw_geometries([point_cloud_0])\n",
    "      \n",
    "    if (i+1) == 2:\n",
    "        break\n",
    "    print(\"Iteration: \",i)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Final view of the stitched object    \n",
    "#point_cloud_0, _ = point_cloud_0.remove_radius_outlier(nb_points=25, radius=0.5)\n",
    "o3d.visualization.draw_geometries([whole_point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_point_cloud\n",
    "current_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([point_cloud_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataloader(dataset_path)\n",
    "\n",
    "pc0 = o3d.geometry.PointCloud()\n",
    "pc1 = o3d.geometry.PointCloud()\n",
    "\n",
    "\n",
    "dmap0, img0 = next(dataset)\n",
    "dmap1, img1 = next(dataset)\n",
    "\n",
    "generate_pointcloud(img0, dmap0, pc0)\n",
    "generate_pointcloud(img1, dmap1, pc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "generate_pointcloud(img0, dmap0, pc0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc0, np.asarray(pc0.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1, np.asarray(pc1.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc0 = pc1 + pc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc0, np.asarray(pc0.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1.points[0] = np.array([100.,100.,100.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = height = 5\n",
    "xyz = np.ones(shape=(height, width, 3))  \n",
    "\n",
    "x = np.arange(width).reshape((1, width))\n",
    "y = np.arange(height).reshape((height, 1))\n",
    "\n",
    "\n",
    "xyz[:, :, 0] = xyz[:, :, 0]*x   \n",
    "xyz[:, :, 1] = xyz[:, :, 1]*y  \n",
    "\n",
    "\n",
    "print(xyz[:,:,0])\n",
    "print()\n",
    "print(xyz[:,:,1])\n",
    "print()\n",
    "print(xyz[:,:,2])\n",
    "\n",
    "xyz = xyz.reshape(width*height, -1)\n",
    "print(xyz)\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is just for visualization purposes to understand how the dataset looks like\n",
    "for i, package in enumerate(dataset):\n",
    "    dmap, wrench_img = package\n",
    "    print('{}, \\t{}'.format(type(dmap), type(wrench_img)))\n",
    "    plt.imshow(dmap)\n",
    "    #cv2.imshow(\"danbots\", wrench_img)\n",
    "    plt.pause(0.1)\n",
    "    plt.draw()\n",
    "    clear_output(wait = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "Currently the dataset consist on 3 loops. Each loop the camera is at a different angle, this means the first 100 picures correspond to one sequence, the next 100 corresponds to another sequence and so on...\n",
    "The first approach given how the data is not continous as a single big trajectory, will be about computing the whole structure/point-cloud for each trajectory and then merging the 3 final point-clouds to get the end results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img0.reshape((160*160, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(pc0.colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized function for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def generate_pointcloud_v3(mask, rgb_file, mydepth, ply_file):\n",
    "    img = Image.open(rgb_file)\n",
    "    img = np.array(img)[:,:,:-1]\n",
    "    \n",
    "    height, width = mydepth.shape\n",
    "    xyz = np.ones(shape=(height, width, 3))  \n",
    "    \n",
    "    x = np.arange(width).reshape((1, width))\n",
    "    y = np.arange(height).reshape((height, 1))\n",
    "    \n",
    "    xyz[:, :, 0] = xyz[:, :, 0]*x                                 # Fill with horizontal indexes\n",
    "    xyz[:, :, 1] = xyz[:, :, 1]*y                                 # Fill with vertical indexes  \n",
    "    \n",
    "    xyz[:, :, 2] = mydepth                                        # Fill with depth, z coords w.r.t camera frame  \n",
    "    xyz[:, :, 0] = 0.1655 * (xyz[:, :, 0]-80) * xyz[:, :, 2]/80   # Updated with x coords w.r.t camera frame \n",
    "    xyz[:, :, 1] = 0.1655 * (xyz[:, :, 1]-80) * xyz[:, :, 2]/80   # Updated with y coords w.r.t camera frame \n",
    "    \n",
    "    xyz = xyz.reshape(width*height, -1)                           # Shape required by open3d\n",
    "    rgb = img.reshape((width*height, -1))\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(xyz)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(rgb)\n",
    "    \n",
    "    o3d.io.write_point_cloud(ply_file, pcd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_img = \"/home/corcasta/Danbots/stitcher/datasets/LA10/render0/image0.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%timeit\n",
    "generate_pointcloud_v3(None, demo_img, dmap0, \"/home/corcasta/Danbots/stitcher/notebooks/data.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.io.read_point_cloud(\"/home/corcasta/Danbots/stitcher/notebooks/data.ply\")\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "danbots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
